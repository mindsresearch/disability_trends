{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main impots\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from IPython.display import HTML\n",
    "import numpy\n",
    "import tensorflow\n",
    "\n",
    "# Test impots\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Alibi docs\n",
    "\n",
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = numpy.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: cmap(norm(x)), attrs))\n",
    "    return colors\n",
    "\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params fo integated gradients\n",
    "n_steps = 50\n",
    "method = 'gausslegendre'\n",
    "internal_batch_size = 100\n",
    "\n",
    "def gen_sent_visual(model, sample, index):\n",
    "    predictions = model(sample).numpy().argmax(axis=1)\n",
    "    gradients = IntegratedGradients(model,\n",
    "                    layer= model.layers[1],\n",
    "                    n_steps=n_steps,\n",
    "                    method=method,\n",
    "                    internal_batch_size=internal_batch_size)\n",
    "    explanation = gradients.explain(\n",
    "                    sample,\n",
    "                    baselines=None,\n",
    "                    target=predictions,\n",
    "                    attribute_to_layer_inputs=False\n",
    "                )\n",
    "\n",
    "    print(explanation.meta)\n",
    "\n",
    "    attrs = explanation.attributions[0]\n",
    "\n",
    "    # probably should be a loop fom here\n",
    "    i = 1\n",
    "    x_i = sample[i]\n",
    "    attrs_i = attrs[i]\n",
    "    pred = predictions[i]\n",
    "    pred_dict = {1: 'Positive review', 0: 'Negative review'}\n",
    "\n",
    "    reverse_index = {value: key for (key, value) in index.items()}\n",
    "    words = \" \".join([reverse_index.get(i - 3, 'UNK') for i in x_i])\n",
    "    colors = colorize(attrs_i)\n",
    "    # to here\n",
    "\n",
    "    HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "maxlen = 100\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - accuracy: 0.5726 - loss: 0.6629 - val_accuracy: 0.8138 - val_loss: 0.4243\n",
      "Epoch 2/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.8529 - loss: 0.3449 - val_accuracy: 0.8499 - val_loss: 0.3513\n",
      "Epoch 3/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.9152 - loss: 0.2215 - val_accuracy: 0.8542 - val_loss: 0.3337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "filepath = './model_imdb/'  # change to directory where model is downloaded\n",
    "if load_model:\n",
    "    model = tensorflow.keras.models.load_model(os.path.join(filepath, 'model.h5'))\n",
    "else:\n",
    "    print('Build model...')\n",
    "\n",
    "    inputs = Input(shape=(maxlen,), dtype=tensorflow.int32)\n",
    "    embedded_sequences = Embedding(max_features,\n",
    "                                   embedding_dims)(inputs)\n",
    "    out = Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1)(embedded_sequences)\n",
    "    out = Dropout(0.4)(out)\n",
    "    out = GlobalMaxPooling1D()(out)\n",
    "    out = Dense(hidden_dims,\n",
    "                activation='relu')(out)\n",
    "    out = Dropout(0.4)(out)\n",
    "    outputs = Dense(2, activation='softmax')(out)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=3,\n",
    "              validation_data=(x_test, y_test))\n",
    "    if save_model:\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        model.save(os.path.join(filepath, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'IntegratedGradients', 'type': ['whitebox'], 'explanations': ['local'], 'params': {'target_fn': None, 'method': 'gausslegendre', 'n_steps': 50, 'internal_batch_size': 100, 'layer': 1}, 'version': '0.9.6'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 15:51:22.064816: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples = 10\n",
    "temp = gen_sent_visual(model, x_test[:nb_samples], imdb.get_word_index())\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(temp, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code ends"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
