{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:01:02.479786: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-04 16:01:02.491793: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-04 16:01:02.546088: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 16:01:03.878759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rags/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Main impots\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from IPython.display import HTML\n",
    "import numpy\n",
    "import tensorflow\n",
    "\n",
    "# Test impots\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Alibi docs\n",
    "\n",
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = numpy.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: cmap(norm(x)), attrs))\n",
    "    return colors\n",
    "\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params fo integated gradients\n",
    "n_steps = 50\n",
    "method = 'gausslegendre'\n",
    "internal_batch_size = 100\n",
    "\n",
    "def gen_sent_visual(model, sample, index):\n",
    "    predictions = model(sample).numpy().argmax(axis=1)\n",
    "    gradients = IntegratedGradients(model,\n",
    "                    layer= model.layers[1],\n",
    "                    n_steps=n_steps,\n",
    "                    method=method,\n",
    "                    internal_batch_size=internal_batch_size)\n",
    "    explanation = gradients.explain(\n",
    "                    sample,\n",
    "                    baselines=None,\n",
    "                    target=predictions,\n",
    "                    attribute_to_layer_inputs=False\n",
    "                )\n",
    "\n",
    "    print(explanation.meta)\n",
    "\n",
    "    attrs = explanation.attributions[0]\n",
    "\n",
    "    # probably should be a loop fom here\n",
    "    i = 1\n",
    "    x_i = sample[i]\n",
    "    attrs_i = attrs[i]\n",
    "    pred = predictions[i]\n",
    "    pred_dict = {1: 'Positive review', 0: 'Negative review'}\n",
    "\n",
    "    reverse_index = {value: key for (key, value) in index.items()}\n",
    "    words = \" \".join([reverse_index.get(i - 3, 'UNK') for i in x_i])\n",
    "    colors = colorize(attrs_i)\n",
    "    # to here\n",
    "\n",
    "    HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "maxlen = 100\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:01:09.096124: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-04 16:01:09.097029: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - accuracy: 0.5657 - loss: 0.6673 - val_accuracy: 0.8169 - val_loss: 0.4273\n",
      "Epoch 2/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.8442 - loss: 0.3581 - val_accuracy: 0.8533 - val_loss: 0.3527\n",
      "Epoch 3/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - accuracy: 0.9117 - loss: 0.2287 - val_accuracy: 0.8528 - val_loss: 0.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "filepath = './model_imdb/'  # change to directory where model is downloaded\n",
    "if load_model:\n",
    "    model = tensorflow.keras.models.load_model(os.path.join(filepath, 'model.h5'))\n",
    "else:\n",
    "    print('Build model...')\n",
    "\n",
    "    inputs = Input(shape=(maxlen,), dtype=tensorflow.int32)\n",
    "    embedded_sequences = Embedding(max_features,\n",
    "                                   embedding_dims)(inputs)\n",
    "    out = Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1)(embedded_sequences)\n",
    "    out = Dropout(0.4)(out)\n",
    "    out = GlobalMaxPooling1D()(out)\n",
    "    out = Dense(hidden_dims,\n",
    "                activation='relu')(out)\n",
    "    out = Dropout(0.4)(out)\n",
    "    outputs = Dense(2, activation='softmax')(out)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=256,\n",
    "              epochs=3,\n",
    "              validation_data=(x_test, y_test))\n",
    "    if save_model:\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        model.save(os.path.join(filepath, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:01:44.711954: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'IntegratedGradients', 'type': ['whitebox'], 'explanations': ['local'], 'params': {'target_fn': None, 'method': 'gausslegendre', 'n_steps': 50, 'internal_batch_size': 100, 'layer': 1}, 'version': '0.9.6'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples = 10\n",
    "temp = gen_sent_visual(model, x_test[:nb_samples], imdb.get_word_index())\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(temp, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code ends"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
